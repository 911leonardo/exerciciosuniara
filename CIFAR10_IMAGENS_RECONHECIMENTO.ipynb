{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/911leonardo/exerciciosuniara/blob/main/CIFAR10_IMAGENS_RECONHECIMENTO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cL8xE4PTrC0t",
        "outputId": "c8975570-13c4-4058-ad4e-dbd9613a8a72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 2s 0us/step\n",
            "Epoch 1/30\n",
            "1563/1563 [==============================] - 63s 39ms/step - loss: 1.4995 - accuracy: 0.4454 - val_loss: 1.1970 - val_accuracy: 0.5735\n",
            "Epoch 2/30\n",
            "1563/1563 [==============================] - 60s 38ms/step - loss: 1.0948 - accuracy: 0.6107 - val_loss: 1.0728 - val_accuracy: 0.6158\n",
            "Epoch 3/30\n",
            "1563/1563 [==============================] - 63s 40ms/step - loss: 0.9264 - accuracy: 0.6740 - val_loss: 0.9193 - val_accuracy: 0.6816\n",
            "Epoch 4/30\n",
            "1563/1563 [==============================] - 64s 41ms/step - loss: 0.8205 - accuracy: 0.7107 - val_loss: 0.9118 - val_accuracy: 0.6792\n",
            "Epoch 5/30\n",
            "1563/1563 [==============================] - 64s 41ms/step - loss: 0.7291 - accuracy: 0.7440 - val_loss: 0.8817 - val_accuracy: 0.6968\n",
            "Epoch 6/30\n",
            "1563/1563 [==============================] - 62s 40ms/step - loss: 0.6550 - accuracy: 0.7704 - val_loss: 0.8598 - val_accuracy: 0.7107\n",
            "Epoch 7/30\n",
            "1563/1563 [==============================] - 62s 39ms/step - loss: 0.5872 - accuracy: 0.7943 - val_loss: 0.8643 - val_accuracy: 0.7210\n",
            "Epoch 8/30\n",
            "1563/1563 [==============================] - 65s 41ms/step - loss: 0.5255 - accuracy: 0.8137 - val_loss: 0.8583 - val_accuracy: 0.7263\n",
            "Epoch 9/30\n",
            "1563/1563 [==============================] - 60s 38ms/step - loss: 0.4689 - accuracy: 0.8338 - val_loss: 0.8929 - val_accuracy: 0.7283\n",
            "Epoch 10/30\n",
            "1563/1563 [==============================] - 59s 38ms/step - loss: 0.4139 - accuracy: 0.8531 - val_loss: 0.9398 - val_accuracy: 0.7192\n",
            "Epoch 11/30\n",
            "1563/1563 [==============================] - 61s 39ms/step - loss: 0.3705 - accuracy: 0.8679 - val_loss: 0.9817 - val_accuracy: 0.7091\n",
            "Epoch 12/30\n",
            "1563/1563 [==============================] - 61s 39ms/step - loss: 0.3217 - accuracy: 0.8861 - val_loss: 1.0530 - val_accuracy: 0.7241\n",
            "Epoch 13/30\n",
            "1563/1563 [==============================] - 61s 39ms/step - loss: 0.2774 - accuracy: 0.9018 - val_loss: 1.1212 - val_accuracy: 0.7202\n",
            "Epoch 14/30\n",
            "1563/1563 [==============================] - 60s 38ms/step - loss: 0.2482 - accuracy: 0.9110 - val_loss: 1.2102 - val_accuracy: 0.7117\n",
            "Epoch 15/30\n",
            "1563/1563 [==============================] - 64s 41ms/step - loss: 0.2174 - accuracy: 0.9209 - val_loss: 1.2740 - val_accuracy: 0.7084\n",
            "Epoch 16/30\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1962 - accuracy: 0.9298 - val_loss: 1.2997 - val_accuracy: 0.7167\n",
            "Epoch 17/30\n",
            "1563/1563 [==============================] - 69s 44ms/step - loss: 0.1809 - accuracy: 0.9356 - val_loss: 1.4346 - val_accuracy: 0.7186\n",
            "Epoch 18/30\n",
            "1563/1563 [==============================] - 65s 42ms/step - loss: 0.1718 - accuracy: 0.9381 - val_loss: 1.4849 - val_accuracy: 0.7221\n",
            "Epoch 19/30\n",
            "1563/1563 [==============================] - 66s 42ms/step - loss: 0.1486 - accuracy: 0.9462 - val_loss: 1.6024 - val_accuracy: 0.7116\n",
            "Epoch 20/30\n",
            "1563/1563 [==============================] - 64s 41ms/step - loss: 0.1503 - accuracy: 0.9470 - val_loss: 1.7324 - val_accuracy: 0.7060\n",
            "Epoch 21/30\n",
            "1563/1563 [==============================] - 58s 37ms/step - loss: 0.1375 - accuracy: 0.9515 - val_loss: 1.7520 - val_accuracy: 0.7049\n",
            "Epoch 22/30\n",
            "1563/1563 [==============================] - 59s 38ms/step - loss: 0.1347 - accuracy: 0.9524 - val_loss: 1.7812 - val_accuracy: 0.7094\n",
            "Epoch 23/30\n",
            "1563/1563 [==============================] - 57s 37ms/step - loss: 0.1341 - accuracy: 0.9542 - val_loss: 1.7875 - val_accuracy: 0.7055\n",
            "Epoch 24/30\n",
            "1563/1563 [==============================] - 57s 37ms/step - loss: 0.1248 - accuracy: 0.9573 - val_loss: 1.9532 - val_accuracy: 0.7007\n",
            "Epoch 25/30\n",
            "1563/1563 [==============================] - 58s 37ms/step - loss: 0.1182 - accuracy: 0.9593 - val_loss: 1.9525 - val_accuracy: 0.7012\n",
            "Epoch 26/30\n",
            "1563/1563 [==============================] - 59s 38ms/step - loss: 0.1275 - accuracy: 0.9568 - val_loss: 2.0019 - val_accuracy: 0.7084\n",
            "Epoch 27/30\n",
            "1563/1563 [==============================] - 59s 38ms/step - loss: 0.1156 - accuracy: 0.9610 - val_loss: 2.2352 - val_accuracy: 0.7009\n",
            "Epoch 28/30\n",
            "1563/1563 [==============================] - 57s 37ms/step - loss: 0.1139 - accuracy: 0.9607 - val_loss: 2.1804 - val_accuracy: 0.7085\n",
            "Epoch 29/30\n",
            "1563/1563 [==============================] - 59s 38ms/step - loss: 0.1097 - accuracy: 0.9628 - val_loss: 2.1869 - val_accuracy: 0.6981\n",
            "Epoch 30/30\n",
            "1563/1563 [==============================] - 59s 38ms/step - loss: 0.1064 - accuracy: 0.9643 - val_loss: 2.3149 - val_accuracy: 0.6971\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 2.3149 - accuracy: 0.6971\n",
            "Test accuracy: 0.6970999836921692\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Carregar os dados CIFAR-10\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
        "\n",
        "# Pré-processamento das imagens\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# Definir o modelo CNN\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compilar o modelo\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Treinar o modelo\n",
        "history = model.fit(train_images, train_labels, epochs=30, validation_data=(test_images, test_labels))\n",
        "\n",
        "# Avaliar o modelo\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "\n",
        "print('Test accuracy:', test_acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G82FOcXWMUa4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('modelo_cifar10.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPiESjh6Ug-9",
        "outputId": "7b72e10f-f0d3-4ead-949c-33eb061dd7c4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Carregar o modelo treinado\n",
        "model = tf.keras.models.load_model('modelo_cifar10.h5')\n",
        "\n",
        "# Carregar uma nova imagem\n",
        "imagemdados = ['aviao','aviao2','cachorro','cachorro2','caminhao','caminhao2','carro','carro2','cavalo','cavalo2','cervo','cervo2','gato','gato2','navio','navio2','passaro','passaro2','sapo','sapo2']\n",
        "for n in imagemdados:\n",
        "  image_path = '/content/dados/'+ n +'.jpg'\n",
        "  img = image.load_img(image_path, target_size=(32, 32))\n",
        "  img_array = image.img_to_array(img)\n",
        "  img_array = np.expand_dims(img_array, axis=0)\n",
        "  img_array /= 255.0\n",
        "\n",
        "#image_path = '/content/dados/teste.jpg'  # Substitua pelo caminho da sua imagem\n",
        "#img = image.load_img(image_path, target_size=(32, 32))\n",
        "#img_array = image.img_to_array(img)\n",
        "#img_array = np.expand_dims(img_array, axis=0)\n",
        "#img_array /= 255.0  # Normalização\n",
        "\n",
        "# Fazer a previsão\n",
        "  prediction = model.predict(img_array)\n",
        "  predicted_class = np.argmax(prediction)\n",
        "\n",
        "# Mapear o número da classe para o nome da classe\n",
        "  class_names = ['avião', 'automóvel', 'pássaro', 'gato', 'cervo', 'cachorro', 'sapo', 'cavalo', 'navio', 'caminhão']\n",
        "  predicted_label = class_names[predicted_class]\n",
        "\n",
        "  print('Predicted class ' + n + ': ', predicted_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlMJgunnsVeR",
        "outputId": "365d5928-90ee-47d6-c25d-c8970707c1a2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 68ms/step\n",
            "Predicted class aviao:  caminhão\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Predicted class aviao2:  avião\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Predicted class cachorro:  cavalo\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Predicted class cachorro2:  gato\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Predicted class caminhao:  caminhão\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Predicted class caminhao2:  caminhão\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Predicted class carro:  caminhão\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Predicted class carro2:  automóvel\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Predicted class cavalo:  cavalo\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Predicted class cavalo2:  avião\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Predicted class cervo:  avião\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Predicted class cervo2:  cervo\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Predicted class gato:  sapo\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Predicted class gato2:  cavalo\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Predicted class navio:  caminhão\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Predicted class navio2:  automóvel\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Predicted class passaro:  avião\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Predicted class passaro2:  pássaro\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Predicted class sapo:  sapo\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Predicted class sapo2:  sapo\n"
          ]
        }
      ]
    }
  ]
}